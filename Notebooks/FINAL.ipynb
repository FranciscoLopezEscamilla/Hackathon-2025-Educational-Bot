{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "openai_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "openai_api_base = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "openai_api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "embeddings_model = os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME')\n",
    "gpt_model = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "index_path = \"../api/index/faiss_index\"\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(azure_endpoint=openai_api_base,\n",
    "                api_key=openai_api_key,\n",
    "                azure_deployment=embeddings_model)\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "                openai_api_version=openai_api_version,\n",
    "                azure_deployment=gpt_model,\n",
    "            )\n",
    "\n",
    "@tool\n",
    "def rag(query:str, k:int = 3):\n",
    "        \"\"\"Use this to execute RAG. If the question is related to gen ai in art or music, using this tool retrieve the results.\"\"\"\n",
    "        print(\"Calling RAG...\")\n",
    "        vector_store = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        \n",
    "        retriever = vector_store.as_retriever()\n",
    "    \n",
    "        template = \"\"\"Answer questions based only on the following context: \n",
    "        \n",
    "        ### CONTEXT ###\n",
    "        {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        If the context doesn't provide enough information to answer the question, say that you don't know.\n",
    "        Do not respond with information outside the previous context.\"\"\"\n",
    "\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "        chain = (\n",
    "            {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        result = chain.invoke(query)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def generate_descriptive_text(input: str):\n",
    "    \"\"\"Analyzes input text and re write it as a description to generate diagrams\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Your job is to analyze this text: {input} \n",
    "    and create a detailed prompt to generate an image of a diagram.\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Prompt for Generating an Image of a Diagram:**\\n\\n---\\n\\n**Title:** Diagram of AI-Driven Art Generation Processes\\n\\n**Description:** Create an informative and visually engaging diagram that illustrates the process of how AI generates art. The diagram should include the following elements:\\n\\n1. **Main Components:**\\n   - **AI Algorithms**: Represent this as a box that connects to other elements, indicating that these algorithms form the foundation for generating art.\\n   - **Autonomous Systems**: Include a section that describes the role of autonomous systems in the art generation process.\\n\\n2. **Generative Art Process:**\\n   - Visualize a flowchart showing the sequence:\\n     - **Code Creation**: An artist writing code.\\n     - **Rules and Processes**: A branch leading to a description of how these rules lead to unique outputs.\\n     - **Execution of Script**: Indicate that running the code generates artwork.\\n\\n3. **Prompt Technology:**\\n   - Illustrate the use of prompt technology with an example:\\n     - **User Inputs**: A box depicting user prompts or commands.\\n     - **AI Response**: An arrow leading to the AI synthesizing content based on these prompts (e.g., \"Midjourney\").\\n     - **Adjustments and Iterations**: Show arrows indicating various iterations leading to the final artwork output.\\n\\n4. **Artistic Media Types:**\\n   - Create a section or a cloud that lists diverse outputs:\\n     - **Digital Graphics**\\n     - **Music**\\n     - **Literature**\\n\\n5. **Complementary Tool Aspect:**\\n   - Include a visual representation (like a gear or tool icon) depicting AI as a complementing tool to human creativity.\\n\\n**Style:** The diagram should be colorful and easy to read, utilizing icons and simple graphics to represent each concept clearly. Use lines and arrows to direct the flow of information, ensuring that it maintains a coherent structure.\\n\\n**Background:** Opt for a clean, light background to enhance readability and focus on the diagrams and text.\\n\\n---\\n\\nThis prompt should guide the generation of a comprehensive and educational diagram that effectively visualizes the complex process of AI-driven art generation as described in the original text.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 441, 'prompt_tokens': 164, 'total_tokens': 605, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_ded0d14823', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-2e3686a3-8076-4296-bea3-29daffcfec07-0', usage_metadata={'input_tokens': 164, 'output_tokens': 441, 'total_tokens': 605, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"'AI can generate art by utilizing algorithms and autonomous systems. These systems create artwork either entirely or partially through computational processes. In the case of generative art, artists often write code that defines rules and processes, which can result in unique artworks every time the script is executed. Additionally, AI can use prompt technology to generate content based on user inputs. For example, some AI systems like Midjourney can produce images based on prompts, incorporating various adjustments and iterations to enhance the final piece. Thus, AI serves as a tool that complements the creative process, allowing for the creation of high-quality artistic media across various forms, including digital graphics, music, and literature.'\"\n",
    "\n",
    "\n",
    "generate_descriptive_text(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "model = os.getenv('GPT_IMAGES_DEPLOYMENT_NAME')\n",
    "images_folder = os.getcwd() + \"\\\\assets\\\\generated_images\"\n",
    "\n",
    "client = AzureOpenAI(azure_endpoint=openai_api_base, \n",
    "                     api_key=openai_api_key, \n",
    "                     api_version=openai_api_version)\n",
    "\n",
    "@tool\n",
    "def generate_images(prompt: str):\n",
    "        \"\"\"Generate images, diagrams, charts, etc., based on prompts\"\"\"\n",
    "\n",
    "        sub_folder = (datetime.today().strftime('%Y-%m-%d %H:%M:%S')).replace(\" \",\"-\").replace(\":\",\"-\")\n",
    "        images_path = os.path.join(images_folder, sub_folder)\n",
    "\n",
    "        if not os.path.exists(images_path):\n",
    "            os.makedirs(images_path) \n",
    "\n",
    "        result = client.images.generate(\n",
    "                    model = model,\n",
    "                    prompt=prompt,\n",
    "                    n=1\n",
    "                    )\n",
    "        \n",
    "        image_url = json.loads(result.model_dump_json())['data'][0]['url']\n",
    "        \n",
    "        image = requests.get(image_url).content\n",
    "        image_name = f\"genai_img_{uuid4()}\"\n",
    "\n",
    "        with open(os.path.join(images_folder, images_path, f\"{image_name}.jpg\"), 'wb') as handler:\n",
    "            handler.write(image)\n",
    "        \n",
    "        return image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_agent = create_react_agent(\n",
    "        model = llm,\n",
    "        tools = [rag],\n",
    "        name = \"rag_agent\"\n",
    "    )\n",
    "\n",
    "descriptive_agent = create_react_agent(\n",
    "        model = llm,\n",
    "        tools = [generate_descriptive_text],\n",
    "        name = \"descriptive_agent\"\n",
    "    )\n",
    "\n",
    "image_agent = create_react_agent(\n",
    "        model = llm,\n",
    "        tools = [generate_images],\n",
    "        name = \"images_agent\"\n",
    "    )\n",
    "\n",
    "workflow = create_supervisor(\n",
    "        agents = [rag_agent, descriptive_agent, image_agent],\n",
    "        model = llm,\n",
    "        prompt= (\"You are a smart assistant. Your have access to multiple agents,\" \n",
    "                 \"your job is to act like a router and decide which agent comes to play.\"\n",
    "                 \"Here is the list of agents: rag_agent, descriptive_agent, images_agent\"\n",
    "                 \"For queries related to gen ai in art, gen ai in music, call the rag_agent\"\n",
    "                 \"If queries are unrelated to the previous topics, say that you don't know.\"\n",
    "                 \"Always handsoff to the descriptive_agent to generate a description for an image based on rag_agent output\"\n",
    "                 \"For image, diagrams, charts, first use rag_agent, then descriptive_agent and finally images_agent\"\n",
    "                 \"Include the last agent response in yours.\"  \n",
    "     )\n",
    "    )\n",
    "\n",
    "app =  workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output from node supervisor \n",
      "----\n",
      "{'messages': [HumanMessage(content='show me a diagram of The research Proces Adapted from Nnizharadze', additional_kwargs={}, response_metadata={}, id='effeb76f-e802-4477-a892-6d3e068db495'), AIMessage(content=\"I don't know.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 135, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_ded0d14823', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='supervisor', id='run-5a01e56c-5a01-48ab-83bd-7f4f55b4cce2-0', usage_metadata={'input_tokens': 135, 'output_tokens': 6, 'total_tokens': 141, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [\"tell me how to create art using generative ai and python\"]}\n",
    "for output in app.stream(inputs):\n",
    "\n",
    "    for key, value in output.items():\n",
    "        print(f\"output from node {key} \")\n",
    "        print(\"----\")\n",
    "        print(value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling RAG...\n",
      "Here are the steps to create art using generative AI and Python, along with a diagram:\n",
      "\n",
      "### Steps to Create Art Using Generative AI and Python\n",
      "\n",
      "1. **Install Python and Required Libraries**:\n",
      "   - Ensure that Python is installed.\n",
      "   - Install necessary libraries (e.g., `matplotlib`, `numpy`) using pip.\n",
      "\n",
      "2. **Define the Generative Art Piece**:\n",
      "   - Determine the concept/design you want to create.\n",
      "\n",
      "3. **Import Required Libraries**:\n",
      "   - In your Python script, import libraries such as `matplotlib` and `numpy`.\n",
      "\n",
      "4. **Create a Blank Canvas**:\n",
      "   - Use `NumPy` to create a blank canvas (array) specifying the desired width and height.\n",
      "\n",
      "5. **Generate the Art**:\n",
      "   - Define parameters for your art piece and iterate through a range of points.\n",
      "   - Use polar coordinates or other mathematical functions to manipulate the canvas.\n",
      "   - Assign random colors to points on the canvas.\n",
      "\n",
      "6. **Display the Generated Art**:\n",
      "   - Use `matplotlib` to visualize the generated art and turn off axes for a clean look.\n",
      "\n",
      "### Simple Diagram\n",
      "![Diagram illustrating steps to create art using generative AI and Python](https://dalleproduse.blob.core.windows.net/private/images/34ec4dc9-34ed-4ef6-9ac9-e25579df13ee/generated_00.png?se=2025-04-10T16%3A22%3A06Z&sig=aYXb4N7Ld2Aazy3Bcq678eEI4oUxbGc8yzHF2ECI3nc%3D&ske=2025-04-16T01%3A26%3A15Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2025-04-09T01%3A26%3A15Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)\n",
      "\n",
      "This diagram represents the steps involved in creating generative art using Python. Each step leads to the next, culminating in the final display of the artwork. If you need any further assistance or modifications, please let me know!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"give me a list of steps to create art using gen ai and python and return a simple diagram\"\n",
    "\n",
    "\n",
    "response = app.invoke({\"messages\":[\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "]})\n",
    "\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
