{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from semantic_kernel.agents import AgentGroupChat, ChatCompletionAgent\n",
    "from semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy import KernelFunctionSelectionStrategy\n",
    "from semantic_kernel.agents.strategies.termination.kernel_function_termination_strategy import KernelFunctionTerminationStrategy\n",
    "#from semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion import AzureChatCompletion\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.agents.open_ai.azure_assistant_agent import AzureAssistantAgent\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from semantic_kernel.functions.kernel_function_from_prompt import KernelFunctionFromPrompt\n",
    "from semantic_kernel.kernel import Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define agents names\n",
    "\n",
    "QUERY_ANALYZER_AGENT = \"analyzer\"\n",
    "TEXT_AGENT = \"text_generator\"\n",
    "IMAGES_AGENT = \"image_generator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kernel_with_chat_completion(service_id: str) -> Kernel:\n",
    "    kernel = Kernel()\n",
    "    kernel.add_service(AzureChatCompletion(\n",
    "        deployment_name=os.getenv('GPT_DEPLOYMENT_NAME'),\n",
    "        api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
    "        api_version=os.getenv('AZURE_OPENAI_VERSION'),\n",
    "        service_id=service_id\n",
    "        \n",
    "    ))\n",
    "\n",
    "    return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion_client = AzureChatCompletion(\n",
    "    api_key=os.getenv('AZURE_OPENAI_KEY'),\n",
    "    deployment_name=os.getenv('GPT_DEPLOYMENT_NAME'),\n",
    "    base_url=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_VERSION')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-05-01-preview'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('AZURE_OPENAI_VERSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_instructions = '''Your job is to read carefully the user query and understand what are the user needs.\n",
    "Determine what kind of document will be helpful in order to help the user learns of the requested topic.\n",
    "\n",
    "Your options can be:\n",
    "- text generation and pdf document\n",
    "- text and image generation and pdf document\n",
    "- text and image generation and ppt presentation\n",
    "- only image generation\n",
    "- flow chart diagram\n",
    "- concept map\n",
    "etc.,\n",
    "\n",
    "Based on query determine what option will fit the best to help the user to learn.\n",
    "'''\n",
    "\n",
    "query_analyzer_agent = ChatCompletionAgent(\n",
    "    service = chat_completion_client,\n",
    "    kernel = create_kernel_with_chat_completion(),\n",
    "    name = QUERY_ANALYZER_AGENT,\n",
    "    instructions = analyzer_instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator_agent = ChatCompletionAgent(\n",
    "    service = chat_completion_client,\n",
    "    kernel = create_kernel_with_chat_completion(),\n",
    "    name = TEXT_AGENT,\n",
    "    instructions = \"Return: Hey this is a sample text agent\"\n",
    ")\n",
    "\n",
    "image_generator_agent = ChatCompletionAgent(\n",
    "    service = chat_completion_client,\n",
    "    kernel = create_kernel_with_chat_completion(),\n",
    "    name = IMAGES_AGENT,\n",
    "    instructions = \"Return: Hey this is a sample images agent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\",\n",
    "    prompt=f\"\"\"Determine which participant takes the next turn in a conversation based on the most recent participant.\n",
    "    State only the name of the participant to take the next turn.\n",
    "    Consider that the {QUERY_ANALYZER_AGENT} always starts first and from there it can choose\n",
    "    the {IMAGES_AGENT}, the {TEXT_AGENT} or both.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMINATION_KEYWORD = \"good\"\n",
    "\n",
    "termination_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"termination\",\n",
    "    prompt=f\"\"\"Examine the final response and check if the user is satisfied with the responses. \n",
    "    If so, respond with this single word without explanation: {TERMINATION_KEYWORD}\n",
    "    \n",
    "RESPONSE:\n",
    "{{{{$history}}}}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = AgentGroupChat(\n",
    "    agents=[query_analyzer_agent, text_generator_agent, image_generator_agent],\n",
    "    selection_strategy=KernelFunctionSelectionStrategy(\n",
    "        function=selection_function,\n",
    "        kernel=create_kernel_with_chat_completion(),\n",
    "        result_parser=lambda result: str(result.value[0]) if result.value is not None else QUERY_ANALYZER_AGENT,\n",
    "        agent_variable_name=\"agents\",\n",
    "        history_variable_name=\"history\"\n",
    "    ),\n",
    "\n",
    "    termination_strategy=KernelFunctionTerminationStrategy(\n",
    "        agents=[query_analyzer_agent],\n",
    "        function=termination_function,\n",
    "        kernel=create_kernel_with_chat_completion(),\n",
    "        result_parser=lambda result: TERMINATION_KEYWORD in str(result.value[0]).lower(),\n",
    "        history_variable_name=\"history\",\n",
    "        maximum_iterations=10\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", NotFoundError(\"Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:87\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     86\u001b[0m         settings_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 87\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_dict)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1927\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1926\u001b[0m validate_response_format(response_format)\n\u001b[1;32m-> 1927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1928\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1929\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[0;32m   1930\u001b[0m         {\n\u001b[0;32m   1931\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m   1934\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1935\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1936\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1937\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1938\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m   1940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m   1942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m   1943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1945\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m   1946\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1947\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m   1948\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1949\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1950\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1951\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m   1953\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1955\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1956\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1957\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1958\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1959\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1960\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1961\u001b[0m         },\n\u001b[0;32m   1962\u001b[0m         completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m   1963\u001b[0m     ),\n\u001b[0;32m   1964\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1965\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1966\u001b[0m     ),\n\u001b[0;32m   1967\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1968\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1969\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[0;32m   1970\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1856\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1853\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1854\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1855\u001b[0m )\n\u001b[1;32m-> 1856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1550\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1551\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1552\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1553\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1554\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1555\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1556\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1651\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1651\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1653\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1654\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1655\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1660\u001b[0m )\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceResponseException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m chat\u001b[38;5;241m.\u001b[39minvoke():\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m # \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrole\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat\u001b[38;5;241m.\u001b[39mis_complete:\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\group_chat\\agent_group_chat.py:156\u001b[0m, in \u001b[0;36mAgentGroupChat.invoke\u001b[1;34m(self, agent, is_joining)\u001b[0m\n\u001b[0;32m    153\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentChatException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to select agent\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke_agent(selected_agent):\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m==\u001b[39m AuthorRole\u001b[38;5;241m.\u001b[39mASSISTANT:\n\u001b[0;32m    158\u001b[0m         task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtermination_strategy\u001b[38;5;241m.\u001b[39mshould_terminate(selected_agent, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mmessages)\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\group_chat\\agent_chat.py:149\u001b[0m, in \u001b[0;36mAgentChat.invoke_agent\u001b[1;34m(self, agent)\u001b[0m\n\u001b[0;32m    146\u001b[0m channel: AgentChannel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_or_create_channel(agent)\n\u001b[0;32m    147\u001b[0m messages: \u001b[38;5;28mlist\u001b[39m[ChatMessageContent] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m is_visible, message \u001b[38;5;129;01min\u001b[39;00m channel\u001b[38;5;241m.\u001b[39minvoke(agent):\n\u001b[0;32m    150\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend(message)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend(message)\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\channels\\chat_history_channel.py:63\u001b[0m, in \u001b[0;36mChatHistoryChannel.invoke\u001b[1;34m(self, agent, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m mutated_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m     61\u001b[0m message_queue: Deque[ChatMessageContent] \u001b[38;5;241m=\u001b[39m deque()\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response_message \u001b[38;5;129;01min\u001b[39;00m agent\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Capture all messages that have been included in the mutated history.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m message_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(message_count, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages)):\n\u001b[0;32m     66\u001b[0m         mutated_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages[message_index]\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\utils\\telemetry\\agent_diagnostics\\decorators.py:43\u001b[0m, in \u001b[0;36mtrace_agent_invocation.<locals>.wrapper_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mdescription:\n\u001b[0;32m     41\u001b[0m     span\u001b[38;5;241m.\u001b[39mset_attribute(gen_ai_attributes\u001b[38;5;241m.\u001b[39mAGENT_DESCRIPTION, agent\u001b[38;5;241m.\u001b[39mdescription)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m invoke_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\chat_completion\\chat_completion_agent.py:189\u001b[0m, in \u001b[0;36mChatCompletionAgent.invoke\u001b[1;34m(self, history, arguments, kernel, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;129m@trace_agent_invocation\u001b[39m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    177\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterable[ChatMessageContent]:\n\u001b[0;32m    178\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Invoke the chat history handler.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m        An async iterable of ChatMessageContent.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_invoke(history, arguments, kernel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\chat_completion\\chat_completion_agent.py:319\u001b[0m, in \u001b[0;36mChatCompletionAgent._inner_invoke\u001b[1;34m(self, history, arguments, kernel, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m message_count_before_completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(agent_chat_history)\n\u001b[0;32m    317\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Invoking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 319\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m chat_completion_service\u001b[38;5;241m.\u001b[39mget_chat_message_contents(\n\u001b[0;32m    320\u001b[0m     chat_history\u001b[38;5;241m=\u001b[39magent_chat_history,\n\u001b[0;32m    321\u001b[0m     settings\u001b[38;5;241m=\u001b[39msettings,\n\u001b[0;32m    322\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m    323\u001b[0m     arguments\u001b[38;5;241m=\u001b[39marguments,\n\u001b[0;32m    324\u001b[0m )\n\u001b[0;32m    326\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Invoked \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith message count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage_count_before_completion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    329\u001b[0m )\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_capture_mutated_messages(history, agent_chat_history, message_count_before_completion)\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\chat_completion_client_base.py:139\u001b[0m, in \u001b[0;36mChatCompletionClientBase.get_chat_message_contents\u001b[1;34m(self, chat_history, settings, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m use_span(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_auto_function_invocation_activity(kernel, settings), end_on_exit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m request_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings\u001b[38;5;241m.\u001b[39mfunction_choice_behavior\u001b[38;5;241m.\u001b[39mmaximum_auto_invoke_attempts):\n\u001b[1;32m--> 139\u001b[0m         completions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_get_chat_message_contents(chat_history, settings)\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\u001b[39;00m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m         function_calls \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m completions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitems \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, FunctionCallContent)]\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\utils\\telemetry\\model_diagnostics\\decorators.py:112\u001b[0m, in \u001b[0;36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(completion_func)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper_decorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[ChatMessageContent]:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     completion_service: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionClientBase\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    115\u001b[0m     chat_history: ChatHistory \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_chat_completion_base.py:88\u001b[0m, in \u001b[0;36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[1;34m(self, chat_history, settings)\u001b[0m\n\u001b[0;32m     85\u001b[0m settings\u001b[38;5;241m.\u001b[39mmessages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat_history_for_request(chat_history)\n\u001b[0;32m     86\u001b[0m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_id\n\u001b[1;32m---> 88\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(settings)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[0;32m     90\u001b[0m response_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_from_chat_response(response)\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:59\u001b[0m, in \u001b[0;36mOpenAIHandler._send_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mTEXT \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mCHAT:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_completion_request(settings)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mEMBEDDING:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIEmbeddingPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\p.a.rodriguez.canedo\\Documents\\Hackaton_2025\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:104\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to complete the prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    101\u001b[0m         ex,\n\u001b[0;32m    102\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to complete the prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    106\u001b[0m         ex,\n\u001b[0;32m    107\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;31mServiceResponseException\u001b[0m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", NotFoundError(\"Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\"))"
     ]
    }
   ],
   "source": [
    "is_complete : bool = False\n",
    "\n",
    "while not is_complete:\n",
    "    user_input = input(\"User:> \")\n",
    "    if not user_input:\n",
    "        print(\"Empty input\")\n",
    "        continue\n",
    "    \n",
    "    if user_input.lower() == \"good\":\n",
    "        print(\"exiting conversation...\")\n",
    "        is_complete= True\n",
    "        break\n",
    "\n",
    "    #await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "\n",
    "    async for response in chat.invoke():\n",
    "        print(f\" # {response.role} - {response.name or '*'} - {response.content}\")\n",
    "    \n",
    "    if chat.is_complete:\n",
    "        print(\"chat is complete\")\n",
    "        is_complete = True\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
